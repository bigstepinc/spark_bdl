<configuration>
  <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:postgresql://POSTGRES_HOSTNAME:POSTGRES_PORT/SPARK_POSTGRES_DB</value>
  </property>
  <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>org.postgresql.Driver</value>
  </property>
  <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>SPARK_POSTGRES_USER</value>
  </property>
  <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>SPARK_POSTGRES_PASSWORD</value>
  </property>
  <property>     
      <name>datanucleus.autoCreateSchema</name>     
      <value>false</value>
  </property>
  
  <!-- Attempt to avoid RPC error -->
  
  <property>
      <name>hive.exec.dynamic.partition</name>
      <value>DYNAMIC_PARTITION_VALUE</value>
  </property>
  <property>
      <name>hive.exec.dynamic.partition.mode</name>
      <value>DYNAMIC_PARTITION_MODE</value>
  </property>
  <property>
      <name>hive.exec.max.dynamic.partitions</name>
      <value>NR_MAX_DYNAMIC_PARTITIONS</value>
  </property>
  <property>
      <name>hive.exec.max.dynamic.partitions.pernode</name>
      <value>MAX_DYNAMIC_PARTITIONS_PER_NODE</value>
  </property>
   <property>
        <name>hive.exec.scratchdir</name>
        <value>file:///tmp/hive/</value>
  </property>
  <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/spark-warehouse</value>
</property>
</configuration>
